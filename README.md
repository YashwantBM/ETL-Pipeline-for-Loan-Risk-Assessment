# ğŸ’° Loan Risk Assessment â€“ ETL Pipeline Project

This project demonstrates an end-to-end ETL pipeline built using **PySpark** and **Spark SQL** to process and analyze loan application data for risk assessment.

---

## ğŸ” Objective

- Clean and transform raw loan application data
- Standardize applicant features
- Compute risk scores for each applicant
- Prepare structured output for analysis and reporting

---

## ğŸ›  Tech Stack

- **PySpark**
- **Spark SQL**
- **Power BI** (for visual summary)
- **CSV** (as data source)

---

## âš™ï¸ Workflow

1. **Extract**: Load raw CSV files containing loan applicant data  
2. **Transform**: Handle missing values, standardize formats, apply business rules  
3. **Load**: Output cleaned data to structured format for further analysis

---

## âœ… Key Highlights

- Built modular ETL functions for maintainability
- Applied data quality checks and filtering logic
- Scored applicants based on key risk indicators
- Designed Power BI reports to summarize loan approval risks

---

## ğŸ“‚ Project Status

âœ”ï¸ Completed  
ğŸ“Š Visualizations created using Power BI  
ğŸ’¡ Suitable for extension into a real-time pipeline or ML integration

---

## ğŸ‘¤ Author

**Yashwant Kumar BM**  
[GitHub](https://github.com/YashwantBM) â€¢ [LinkedIn](https://linkedin.com/in/yashwantkumarbm)
